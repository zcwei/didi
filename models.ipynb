{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data', (152251, 21))\n",
      "('weather_train', (2528, 5))\n",
      "('traffic_train', (184264, 7))\n",
      "('train_data', (152251, 21))\n",
      "('test_data', (2838, 22))\n"
     ]
    }
   ],
   "source": [
    "## direct read the small test set and training set from the pickle file\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "pickle_file = 'train_data.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  orders_train = save['orders_train']\n",
    "  weather_train = save['weather_train'] \n",
    "  traffic_train = save['traffic_train']\n",
    "  train_data = save['train_data']\n",
    "  test_data = save['test_data']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('train_data', train_data.shape)\n",
    "  print('weather_train', weather_train.shape)\n",
    "  print('traffic_train', traffic_train.shape)\n",
    "  print('train_data', train_data.shape)\n",
    "  print('test_data', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.time_slot > 40]\n",
    "x= train_data.drop(['gap', 'date'], axis = 1)\n",
    "y =train_data.gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "    return top_scores[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###search for the best parameters\n",
    "def run_randomsearch(X, y, clf, para_dist, cv=5,\n",
    "                     n_iter_search=20):\n",
    "    \"\"\"Run a random search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_dist -- [dict] list, distributions of parameters\n",
    "                  to sample\n",
    "    cv -- fold of cross-validation, default 5\n",
    "    n_iter_search -- number of random parameter sets to try,\n",
    "                     default 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(clf,\n",
    "                        param_distributions=param_dist,\n",
    "                        n_iter=n_iter_search)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print((\"\\nRandomizedSearchCV took {:.2f} seconds \"\n",
    "           \"for {:d} candidates parameter settings.\").format((time() - start), n_iter_search))\n",
    "\n",
    "    top_params = report(random_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV took 51240.56 seconds for 50 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.981 (std: 0.002)\n",
      "Parameters: {'max_features': 14, 'min_samples_split': 9, 'n_estimators': 850}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.981 (std: 0.002)\n",
      "Parameters: {'max_features': 14, 'min_samples_split': 9, 'n_estimators': 913}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.980 (std: 0.002)\n",
      "Parameters: {'max_features': 14, 'min_samples_split': 12, 'n_estimators': 325}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###very time consuming step \n",
    "param_dist = {\"n_estimators\": randint(100, 1000),\n",
    "              \"max_features\": randint(3, 15),\n",
    "              \"min_samples_split\": randint(1, 20)}\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "ts_rs = run_randomsearch(x, y, regressor, param_dist, cv=10, n_iter_search=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##random forest \n",
    "regressor = RandomForestRegressor(n_estimators=850, max_features =14,  min_samples_split=9)\n",
    "##regressor.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.556 (std: 0.275)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import  cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "##custom scoring function \n",
    "def mape(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = y\n",
    "    df['y_pred'] = y_pred\n",
    "    df.y_pred[df.y_pred == 0] = 1  ##need set the value to at least 1 \n",
    "    df = df.round()\n",
    "    df = df[df.y != 0]\n",
    "    return ((np.sum(np.abs(df.y-df.y_pred)/df.y)/df.shape[0]))\n",
    "    \n",
    "scores = cross_val_score(regressor,x, y, cv=10, scoring=mape)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##output predict values\n",
    "# prepare prediction\n",
    "x = test_data[['time_slot', 'start_district_id','demand','supply', 'dayType', 'Weather','Temperature','PM25','lv1','lv2','lv3','lv4','t-1','t-2','t-3','lv1_pect','lv2_pect','lv3_pect','lv4_pect']]\n",
    "result = regressor.predict(x)\n",
    "result =result.round()\n",
    "result[result == 0] = 1 \n",
    "\n",
    "final_result = pd.DataFrame(test_data)\n",
    "final_result['gap'] = result\n",
    "final_result.sort(['date', 'time_slot', 'start_district_id'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combinedTimeDistrict = lambda x: (x.date.strftime('%Y-%m-%d'))+'-'+str(x.time_slot)\n",
    "    \n",
    "final_result['Time_district'] = final_result.apply(combinedTimeDistrict, axis=1)\n",
    "final_result.to_csv('result.csv',columns=['start_district_id', 'Time_district', 'gap'], header = False, index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
